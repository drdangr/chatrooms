interface Message {
  role: 'system' | 'user' | 'assistant'
  content: string
}

interface ChatCompletionResponse {
  choices: Array<{
    message: {
      role: string
      content: string
    }
  }>
}

interface ListModelsResponse {
  data: Array<{
    id: string
    object: string
  }>
}

/**
 * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å –º–æ–¥–µ–ª—å—é o1/o3 (reasoning model)
 * –ú–æ–¥–µ–ª–∏ o1/o3 –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏ —Ç—Ä–µ–±—É—é—Ç –æ—Å–æ–±–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
 * 
 * –í–ê–ñ–ù–û: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –º–æ–¥–µ–ª–µ–π –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ OpenAI:
 * - –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è –ø—Ä–æ—Å—Ç–æ 'o1' –≤–º–µ—Å—Ç–æ 'o1-preview'
 * - –¢—Ä–µ–±—É–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ API –∫–ª—é—á
 * - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: https://platform.openai.com/docs/models
 */
function isO1Model(model: string): boolean {
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏ o1/o3 (o1, o1-preview, o1-mini, o3 –∏ —Ç.–¥.)
  return model.startsWith('o1') || model.startsWith('o3') || model.includes('o1-') || model.includes('o3-')
}

/**
 * –ù–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, GPT-5) —Ç—Ä–µ–±—É—é—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ max_completion_tokens –≤–º–µ—Å—Ç–æ max_tokens
 */
function usesMaxCompletionTokens(model: string): boolean {
  return model.startsWith('gpt-5') || model.startsWith('gpt-4.1')
}

/**
 * –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, GPT-5) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É temperature
 */
function supportsCustomTemperature(model: string, isO1: boolean): boolean {
  if (isO1) return false
  return !model.startsWith('gpt-5')
}

function sanitizeTemperature(temp?: number): number {
  if (typeof temp !== 'number' || Number.isNaN(temp)) {
    return 0.7
  }

  return Math.min(2, Math.max(0, temp))
}

/**
 * –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π o1
 * –ú–æ–¥–µ–ª–∏ o1 –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è - —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –≤ –ø–µ—Ä–≤–æ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
 */
function formatMessagesForO1(
  systemPrompt: string,
  messages: Array<{ sender_name: string; text: string }>
): Message[] {
  const formattedMessages: Message[] = []
  
  // –í—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
  const systemInstruction = systemPrompt?.trim() || '–í—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'
  
  if (messages.length === 0) {
    // –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–∑–¥–∞–µ–º –æ–¥–Ω–æ —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
    formattedMessages.push({
      role: 'user',
      content: systemInstruction,
    })
  } else {
    // –í—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    const firstMessage = messages[0]
    formattedMessages.push({
      role: 'user',
      content: `${systemInstruction}\n\n${firstMessage.sender_name}: ${firstMessage.text}`,
    })
    
    // –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
    for (let i = 1; i < messages.length; i++) {
      formattedMessages.push({
        role: 'user',
        content: `${messages[i].sender_name}: ${messages[i].text}`,
      })
    }
  }
  
  return formattedMessages
}

/**
 * –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)
 */
function formatMessagesForStandard(
  systemPrompt: string,
  messages: Array<{ sender_name: string; text: string }>
): Message[] {
  const formattedMessages: Message[] = [
    {
      role: 'system',
      content: systemPrompt || '–í—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.',
    },
  ]

  // Convert chat messages to OpenAI format
  messages.forEach((msg) => {
    formattedMessages.push({
      role: 'user',
      content: `${msg.sender_name}: ${msg.text}`,
    })
  })

  return formattedMessages
}

export async function callOpenAI(
  systemPrompt: string,
  messages: Array<{ sender_name: string; text: string }>,
  model: string = 'gpt-4o-mini',
  temperature?: number
): Promise<string> {
  const apiKey = import.meta.env.VITE_OPENAI_API_KEY

  if (!apiKey) {
    throw new Error('OpenAI API key is not configured')
  }

  const isO1 = isO1Model(model)
  const supportsTemperature = supportsCustomTemperature(model, isO1)
  const sanitizedTemperature = sanitizeTemperature(temperature)
  
  // –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
  const formattedMessages = isO1
    ? formatMessagesForO1(systemPrompt, messages)
    : formatMessagesForStandard(systemPrompt, messages)

  // –õ–æ–≥–∏—Ä—É–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
  console.log('üì§ OpenAI API request:', {
    model,
    isO1Model: isO1,
    messagesCount: formattedMessages.length,
    firstMessagePreview: formattedMessages[0]?.content?.substring(0, 100),
    hasSystemPrompt: !isO1 && formattedMessages[0]?.role === 'system',
    temperature: supportsTemperature ? sanitizedTemperature : 'default',
  })

  // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ - –º–æ–¥–µ–ª–∏ o1 –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç temperature
  const requestBody: any = {
    model: model,
    messages: formattedMessages,
  }

  // –î–ª—è –º–æ–¥–µ–ª–µ–π o1 –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º temperature (–æ–Ω–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç —ç—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä)
  if (!isO1) {
    if (supportsTemperature) {
      requestBody.temperature = sanitizedTemperature
    }
    if (usesMaxCompletionTokens(model)) {
      requestBody.max_completion_tokens = 1000
    } else {
      requestBody.max_tokens = 1000
    }
  } else {
    // –î–ª—è –º–æ–¥–µ–ª–µ–π o1 –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å max_tokens, –Ω–æ –æ–±—ã—á–Ω–æ —ç—Ç–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    // –û–Ω–∏ —É–ø—Ä–∞–≤–ª—è—é—Ç –¥–ª–∏–Ω–æ–π –æ—Ç–≤–µ—Ç–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
  }

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify(requestBody),
    })

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      const errorMessage = errorData.error?.message || `OpenAI API error: ${response.status} ${response.statusText}`
      
      // –ë–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö –¥–ª—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
      if (errorMessage.includes('does not exist') || errorMessage.includes('not found')) {
        throw new Error(
          `–ú–æ–¥–µ–ª—å "${model}" –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n` +
          `1. –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ —á–µ—Ä–µ–∑ API –∫–ª—é—á\n` +
          `2. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏ (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é OpenAI)\n` +
          `3. –ú–æ–¥–µ–ª—å –µ—â–µ –Ω–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –¥–ª—è API\n\n` +
          `–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: ${errorMessage}`
        )
      }
      
      throw new Error(errorMessage)
    }

    const data: ChatCompletionResponse = await response.json()

    if (!data.choices || data.choices.length === 0) {
      throw new Error('No response from OpenAI')
    }

    return data.choices[0].message.content.trim()
  } catch (error) {
    console.error('OpenAI API error:', error)
    throw error
  }
}

/**
 * –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ API –∫–ª—é—á–∞
 */
export async function listOpenAIModels(): Promise<string[]> {
  const apiKey = import.meta.env.VITE_OPENAI_API_KEY

  if (!apiKey) {
    throw new Error('OpenAI API key is not configured')
  }

  try {
    const response = await fetch('https://api.openai.com/v1/models', {
      method: 'GET',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
      },
    })

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      const errorMessage = errorData.error?.message || `OpenAI API error: ${response.status} ${response.statusText}`
      throw new Error(errorMessage)
    }

    const data: ListModelsResponse = await response.json()
    return data.data.map((model) => model.id)
  } catch (error) {
    console.error('Failed to fetch OpenAI models:', error)
    throw error
  }
}

